{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vahidghorbanian/MNIST-calssification/blob/master/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw6hZy_XFOd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e120410a-51f0-4c92-ff81-0c027c23cd0d"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 5.0MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LznOG7BkJCd9",
        "colab_type": "code",
        "outputId": "e19e626a-b438-48f9-f679-2156e8130e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1dihCpOHMbb",
        "colab_type": "code",
        "outputId": "f0a9c91c-8e8e-40a8-cddc-fcff6d8a2e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd drive\n",
        "%cd My\\ Drive\n",
        "%cd python"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9tdXJeoJaxu",
        "colab_type": "code",
        "outputId": "ba84d3a1-9fb0-475e-e6e2-cf396aa55f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note that the number of training and test samples should be reduced to run the algorithm faster. \n",
            "\n",
            "******************************************\n",
            "Logistic Regression is running...\n",
            "\n",
            "C =  1\n",
            "Logisitic Regression fit done!\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "run time:  49.10945105552673\n",
            "Test scores:  [0.862]\n",
            "\n",
            "******************************************\n",
            "KNN is running...\n",
            "The Euclidian distance (L2) is used.\n",
            "\n",
            "k =  3\n",
            "KNN fit done!\n",
            "run time:  9.217334747314453\n",
            "\n",
            "k =  10\n",
            "KNN fit done!\n",
            "run time:  9.278750658035278\n",
            "Test scores:  [0.924, 0.918]\n",
            "\n",
            "******************************************\n",
            "Decision Tree is running...\n",
            "\n",
            "depth =  None\n",
            "Decision Tree fit done!\n",
            "run time:  2.168137788772583\n",
            "Test scores:  [0.802]\n",
            "\n",
            "******************************************\n",
            "Random forest is running...\n",
            "\n",
            "depth =  None\n",
            "Random forest fit done!\n",
            "run time for depth=None:  5.244737386703491\n",
            "Test scores:  [0.944]\n",
            "\n",
            "******************************************\n",
            "AdaBoost is running...\n",
            "\n",
            "base estimator =  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
            "                       max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort=False,\n",
            "                       random_state=0, splitter='best')\n",
            "Ada Boost fit done!\n",
            "run time:  20.43211555480957\n",
            "Test scores:  [0.59]\n",
            "\n",
            "******************************************\n",
            "SVM is running...\n",
            "\n",
            "kernel = linear , C = 1\n",
            "SVC fit done!\n",
            "run time:  16.93812370300293\n",
            "\n",
            "kernel = linear , C = 10\n",
            "SVC fit done!\n",
            "run time:  16.822160482406616\n",
            "\n",
            "kernel = linear , C = 100\n",
            "SVC fit done!\n",
            "run time:  16.82330846786499\n",
            "\n",
            "kernel = linear , C = 1000\n",
            "SVC fit done!\n",
            "run time:  16.817753314971924\n",
            "\n",
            "kernel = linear , C = 10000\n",
            "SVC fit done!\n",
            "run time:  16.862144947052002\n",
            "\n",
            "kernel = poly , C = 1\n",
            "SVC fit done!\n",
            "run time:  43.13508987426758\n",
            "\n",
            "kernel = poly , C = 10\n",
            "SVC fit done!\n",
            "run time:  43.06010413169861\n",
            "\n",
            "kernel = poly , C = 100\n",
            "SVC fit done!\n",
            "run time:  43.14031624794006\n",
            "\n",
            "kernel = poly , C = 1000\n",
            "SVC fit done!\n",
            "run time:  43.09196662902832\n",
            "\n",
            "kernel = poly , C = 10000\n",
            "SVC fit done!\n",
            "run time:  43.23554587364197\n",
            "\n",
            "kernel = rbf , C = 1\n",
            "SVC fit done!\n",
            "run time:  27.320392370224\n",
            "\n",
            "kernel = rbf , C = 10\n",
            "SVC fit done!\n",
            "run time:  27.483635187149048\n",
            "\n",
            "kernel = rbf , C = 100\n",
            "SVC fit done!\n",
            "run time:  27.264289379119873\n",
            "\n",
            "kernel = rbf , C = 1000\n",
            "SVC fit done!\n",
            "run time:  27.286535263061523\n",
            "\n",
            "kernel = rbf , C = 10000\n",
            "SVC fit done!\n",
            "run time:  27.468931913375854\n",
            "Test scores:  [[0.916, 0.916, 0.916, 0.916, 0.916, 0.81, 0.81, 0.81, 0.81, 0.81, 0.964, 0.964, 0.964, 0.964, 0.964], [0.916, 0.916, 0.916, 0.916, 0.916, 0.81, 0.81, 0.81, 0.81, 0.81, 0.964, 0.964, 0.964, 0.964, 0.964], [0.916, 0.916, 0.916, 0.916, 0.916, 0.81, 0.81, 0.81, 0.81, 0.81, 0.964, 0.964, 0.964, 0.964, 0.964]]\n",
            "\n",
            "******************************************\n",
            "fully connected neural net is running...\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 16:24:05.528272 140699698173824 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "\n",
            "num.dense layers=  2  num.neurons= 500  l1= 0.0  l2= 0.0\n",
            "Early Stopping activated!\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "W0718 16:24:05.704232 140699698173824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-07-18 16:24:05.948850: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-07-18 16:24:05.953158: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a768380 executing computations on platform Host. Devices:\n",
            "2019-07-18 16:24:05.953203: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-18 16:24:05.959834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-18 16:24:06.169576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 16:24:06.170077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a768700 executing computations on platform CUDA. Devices:\n",
            "2019-07-18 16:24:06.170105: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-07-18 16:24:06.170316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 16:24:06.170690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-18 16:24:06.186272: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-18 16:24:06.366641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-18 16:24:06.451863: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-18 16:24:06.477116: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-18 16:24:06.684005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-18 16:24:06.810137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-18 16:24:07.182827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-18 16:24:07.183042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 16:24:07.183552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 16:24:07.183924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-18 16:24:07.187225: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-18 16:24:07.189335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-18 16:24:07.189369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-18 16:24:07.189381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-18 16:24:07.192221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 16:24:07.192681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 16:24:07.193201: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-18 16:24:07.193287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Epoch 1/200\n",
            "2019-07-18 16:24:08.978521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "8000/8000 [==============================] - 1s 181us/sample - loss: 1.7583 - acc: 0.5834 - val_loss: 1.1420 - val_acc: 0.7670\n",
            "Epoch 2/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.8388 - acc: 0.8226 - val_loss: 0.6922 - val_acc: 0.8270\n",
            "Epoch 3/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5964 - acc: 0.8565 - val_loss: 0.5891 - val_acc: 0.8470\n",
            "Epoch 4/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.5009 - acc: 0.8701 - val_loss: 0.5232 - val_acc: 0.8645\n",
            "Epoch 5/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.4640 - acc: 0.8742 - val_loss: 0.4810 - val_acc: 0.8700\n",
            "Epoch 6/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.4109 - acc: 0.8851 - val_loss: 0.4786 - val_acc: 0.8670\n",
            "Epoch 7/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3876 - acc: 0.8914 - val_loss: 0.4608 - val_acc: 0.8615\n",
            "Epoch 8/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3834 - acc: 0.8896 - val_loss: 0.4450 - val_acc: 0.8725\n",
            "Epoch 9/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3588 - acc: 0.8967 - val_loss: 0.4316 - val_acc: 0.8700\n",
            "Epoch 10/200\n",
            "8000/8000 [==============================] - 1s 79us/sample - loss: 0.3636 - acc: 0.8926 - val_loss: 0.4247 - val_acc: 0.8750\n",
            "Epoch 11/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3570 - acc: 0.8955 - val_loss: 0.4182 - val_acc: 0.8820\n",
            "Epoch 12/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3473 - acc: 0.8969 - val_loss: 0.4088 - val_acc: 0.8805\n",
            "Epoch 13/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3304 - acc: 0.9045 - val_loss: 0.4081 - val_acc: 0.8850\n",
            "Epoch 14/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3407 - acc: 0.8960 - val_loss: 0.4080 - val_acc: 0.8855\n",
            "Epoch 15/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3179 - acc: 0.9056 - val_loss: 0.4251 - val_acc: 0.8810\n",
            "Epoch 16/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3261 - acc: 0.9005 - val_loss: 0.4135 - val_acc: 0.8745\n",
            "Epoch 17/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3208 - acc: 0.9047 - val_loss: 0.3997 - val_acc: 0.8855\n",
            "Epoch 18/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3249 - acc: 0.9061 - val_loss: 0.4329 - val_acc: 0.8745\n",
            "Epoch 19/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3255 - acc: 0.9013 - val_loss: 0.3851 - val_acc: 0.8950\n",
            "Epoch 20/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3061 - acc: 0.9068 - val_loss: 0.3980 - val_acc: 0.8850\n",
            "Epoch 21/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3103 - acc: 0.9072 - val_loss: 0.4083 - val_acc: 0.8885\n",
            "Epoch 22/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3042 - acc: 0.9089 - val_loss: 0.3955 - val_acc: 0.8800\n",
            "Epoch 23/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3051 - acc: 0.9080 - val_loss: 0.4145 - val_acc: 0.8830\n",
            "Epoch 24/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3169 - acc: 0.9036 - val_loss: 0.4021 - val_acc: 0.8865\n",
            "Epoch 25/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3008 - acc: 0.9061 - val_loss: 0.3824 - val_acc: 0.8920\n",
            "Epoch 26/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2727 - acc: 0.9183 - val_loss: 0.3542 - val_acc: 0.9000\n",
            "Epoch 27/200\n",
            "8000/8000 [==============================] - 1s 80us/sample - loss: 0.2635 - acc: 0.9216 - val_loss: 0.3555 - val_acc: 0.8975\n",
            "Epoch 28/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.2515 - acc: 0.9250 - val_loss: 0.3492 - val_acc: 0.8975\n",
            "Epoch 29/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.2552 - acc: 0.9215 - val_loss: 0.3517 - val_acc: 0.9020\n",
            "Epoch 30/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2570 - acc: 0.9230 - val_loss: 0.3644 - val_acc: 0.8885\n",
            "Epoch 31/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2732 - acc: 0.9144 - val_loss: 0.3832 - val_acc: 0.8810\n",
            "Epoch 32/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2820 - acc: 0.9111 - val_loss: 0.3901 - val_acc: 0.8875\n",
            "Epoch 33/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2840 - acc: 0.9109 - val_loss: 0.3785 - val_acc: 0.8870\n",
            "Epoch 34/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2589 - acc: 0.9229 - val_loss: 0.3828 - val_acc: 0.8900\n",
            "Epoch 35/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2548 - acc: 0.9231 - val_loss: 0.3893 - val_acc: 0.8885\n",
            "Epoch 36/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2517 - acc: 0.9230 - val_loss: 0.3834 - val_acc: 0.8880\n",
            "Epoch 37/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2704 - acc: 0.9171 - val_loss: 0.3628 - val_acc: 0.8990\n",
            "Epoch 38/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.2557 - acc: 0.9221 - val_loss: 0.3768 - val_acc: 0.8840\n",
            "Epoch 39/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2565 - acc: 0.9226 - val_loss: 0.3480 - val_acc: 0.8965\n",
            "Epoch 40/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2482 - acc: 0.9261 - val_loss: 0.3493 - val_acc: 0.8885\n",
            "Epoch 41/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2494 - acc: 0.9222 - val_loss: 0.3505 - val_acc: 0.8905\n",
            "Epoch 42/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2393 - acc: 0.9246 - val_loss: 0.3412 - val_acc: 0.8965\n",
            "Epoch 43/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.2217 - acc: 0.9331 - val_loss: 0.3368 - val_acc: 0.9050\n",
            "Epoch 44/200\n",
            "8000/8000 [==============================] - 1s 78us/sample - loss: 0.2303 - acc: 0.9277 - val_loss: 0.3549 - val_acc: 0.8980\n",
            "Epoch 45/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2446 - acc: 0.9221 - val_loss: 0.3601 - val_acc: 0.8890\n",
            "Epoch 46/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2423 - acc: 0.9233 - val_loss: 0.3497 - val_acc: 0.8945\n",
            "Epoch 47/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2251 - acc: 0.9329 - val_loss: 0.3418 - val_acc: 0.8995\n",
            "Epoch 48/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2169 - acc: 0.9342 - val_loss: 0.3295 - val_acc: 0.9000\n",
            "Epoch 49/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2342 - acc: 0.9269 - val_loss: 0.3507 - val_acc: 0.8950\n",
            "Epoch 50/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2383 - acc: 0.9277 - val_loss: 0.3423 - val_acc: 0.8950\n",
            "Epoch 51/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.2281 - acc: 0.9289 - val_loss: 0.3460 - val_acc: 0.8960\n",
            "Epoch 52/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2123 - acc: 0.9360 - val_loss: 0.3427 - val_acc: 0.9010\n",
            "Epoch 53/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2155 - acc: 0.9359 - val_loss: 0.3352 - val_acc: 0.9010\n",
            "Epoch 54/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2221 - acc: 0.9309 - val_loss: 0.3208 - val_acc: 0.9090\n",
            "Epoch 55/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2191 - acc: 0.9295 - val_loss: 0.3454 - val_acc: 0.8915\n",
            "Epoch 56/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2203 - acc: 0.9311 - val_loss: 0.3365 - val_acc: 0.9040\n",
            "Epoch 57/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2092 - acc: 0.9350 - val_loss: 0.3358 - val_acc: 0.8995\n",
            "Epoch 58/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.1946 - acc: 0.9391 - val_loss: 0.2996 - val_acc: 0.9085\n",
            "Epoch 59/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.1934 - acc: 0.9409 - val_loss: 0.3235 - val_acc: 0.9010\n",
            "Epoch 60/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.1939 - acc: 0.9389 - val_loss: 0.3347 - val_acc: 0.9040\n",
            "Epoch 61/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.1937 - acc: 0.9419 - val_loss: 0.3176 - val_acc: 0.9055\n",
            "Epoch 62/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.1904 - acc: 0.9427 - val_loss: 0.3261 - val_acc: 0.9060\n",
            "Epoch 63/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2012 - acc: 0.9404 - val_loss: 0.3223 - val_acc: 0.9065\n",
            "Epoch 64/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.1997 - acc: 0.9398 - val_loss: 0.3159 - val_acc: 0.9125\n",
            "Epoch 65/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.1903 - acc: 0.9430 - val_loss: 0.2910 - val_acc: 0.9135\n",
            "Epoch 66/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.1967 - acc: 0.9381 - val_loss: 0.3223 - val_acc: 0.9035\n",
            "Epoch 67/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.2075 - acc: 0.9355 - val_loss: 0.3169 - val_acc: 0.9105\n",
            "Epoch 68/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2155 - acc: 0.9300 - val_loss: 0.3265 - val_acc: 0.9065\n",
            "Epoch 69/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2049 - acc: 0.9364 - val_loss: 0.3218 - val_acc: 0.9120\n",
            "Epoch 70/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2052 - acc: 0.9377 - val_loss: 0.3078 - val_acc: 0.9115\n",
            "Epoch 71/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.2050 - acc: 0.9376 - val_loss: 0.3432 - val_acc: 0.8990\n",
            "Epoch 72/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.2132 - acc: 0.9354 - val_loss: 0.3255 - val_acc: 0.9075\n",
            "Epoch 73/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.1942 - acc: 0.9400 - val_loss: 0.3238 - val_acc: 0.9085\n",
            "Epoch 74/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.1991 - acc: 0.9392 - val_loss: 0.3162 - val_acc: 0.9105\n",
            "Epoch 75/200\n",
            "8000/8000 [==============================] - 1s 74us/sample - loss: 0.1859 - acc: 0.9419 - val_loss: 0.3142 - val_acc: 0.9065\n",
            "Epoch 76/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.1833 - acc: 0.9436 - val_loss: 0.3142 - val_acc: 0.9135\n",
            "Epoch 77/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.1934 - acc: 0.9394 - val_loss: 0.3276 - val_acc: 0.9020\n",
            "Epoch 78/200\n",
            "8000/8000 [==============================] - 1s 78us/sample - loss: 0.1929 - acc: 0.9401 - val_loss: 0.3250 - val_acc: 0.9015\n",
            "Epoch 79/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.1860 - acc: 0.9417 - val_loss: 0.3234 - val_acc: 0.9080\n",
            "Epoch 80/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.1869 - acc: 0.9420 - val_loss: 0.3156 - val_acc: 0.9125\n",
            "Epoch 81/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.1755 - acc: 0.9477 - val_loss: 0.3164 - val_acc: 0.9115\n",
            "Epoch 82/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.1718 - acc: 0.9477 - val_loss: 0.3309 - val_acc: 0.9020\n",
            "Epoch 83/200\n",
            "8000/8000 [==============================] - 1s 75us/sample - loss: 0.1839 - acc: 0.9421 - val_loss: 0.3255 - val_acc: 0.9035\n",
            "Epoch 84/200\n",
            "8000/8000 [==============================] - 1s 77us/sample - loss: 0.1881 - acc: 0.9427 - val_loss: 0.3206 - val_acc: 0.9080\n",
            "Epoch 85/200\n",
            "8000/8000 [==============================] - 1s 76us/sample - loss: 0.1805 - acc: 0.9425 - val_loss: 0.3159 - val_acc: 0.9095\n",
            "\n",
            "calculate test score\n",
            "500/500 [==============================] - 0s 41us/sample - loss: 0.3255 - acc: 0.9060\n",
            "number of hidden units: [500]\n",
            "test scores:\n",
            " [[[0.32551409769058226, 0.906]]]\n",
            "\n",
            "The results are only plotted for the first trained NN model.\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 1500x800 with 42 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}